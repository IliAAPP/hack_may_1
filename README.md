На данный момент репозиторий включает часть МОДЕЛЕЙ, помогающих ограничить детей от нежелательного контента.

- metadata_rus.py отвечает за извлечение метаданных путем парсинга и анализ токсичности содержания (нецензурная брань, оскорбления и прочие подобные вещи, нежелательные для просмотра ребенком, детектятся и удаляются). Предобученная модель - RuBERT (обучена на русском датасете).

- metadata.py отвечает за извлечение метаданных путем парсинга и анализ токсичности содержания (нецензурная брань, оскорбления и прочие подобные вещи, нежелательные для просмотра ребенком, детектятся и удаляются). Предобученная модель - DistilBERT (обучена на английском датасете).

- metadata_together.py - это скрипт, который объединяет функциональность двух моделей. В зависимости от языка текста, извлеченного из видео, скрипт выбирает соответствующую модель для анализа. Если текст на русском языке, применяется модель RuBERT, обученная на задаче оценки токсичности текста. В случае английского текста используется модель DistilBERT, предобученная на данных SST-2 для анализа эмоциональной окраски текста.

- classif_art.py,  classif_art2.py- создается и обучается модель на основе метода наивного Байеса (Multinomial Naive Bayes) с использованием метода TF-IDF для векторизации текста с целью предсказания жанра видео по его содержанию.
Вторая версия полностью - рабочая модель, первая - как пример с текстом из файла.

